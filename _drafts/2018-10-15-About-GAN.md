---
layout: post
title: "About Generative Adversarial Networks"
category: Machine Learning
tags: [neural network]
date: 2018-10-15
---

1. 从网络结构上来说，Generative Adversarial Networks（GAN）并没有创造什么全新的东西。以生成图像为例，GAN其实就是一个反向的CNN用于生成图片加上一个DNN用于决策判别。

2. GAN的训练过程比较微妙，因为它涉及到两个相对独立的神经网络的训练：生成网络（generator）的训练依赖于判别网络（discriminator）的输出，而判别网络的训练又依赖于生成网络的输出。感觉似乎是一个死循环，但实际上却是可以训练的，具体过程如下：

   > Step 1) Set the discriminator trainable
   >
   > Step 2) Train the discriminator with the real MNIST digit images and the images generated by the generator to classify the real and fake images.
   >
   > Step 3) Set the discriminator non-trainable
   >
   > Step 4) Train the generator as part of the GAN. We feed latent samples into the GAN and let the generator to produce digit images and use the discriminator to classify the image.

   在上述四个步骤完成之后（即步骤2训练的判别网络和步骤4训练的生成网络的损失都达到了比较小的值），需要再回到步骤1，以此反复地训练判别网络和生成网络。最终的目标是无论如何训练判别网络，它都很难区分出生成网络的输出和真实的样本（即任意输入一个真实样本或生成网络的输出，判别网络输出它的真实概率均为0.5（概率范围为0到1））。

3. 对于生成图像的反向CNN，它是如何从少量的输入扩展到一张高分辨率的图片的呢？因为是反向的，卷积层其实也要“反”过来，具体做法以输入为4x4的图像为例，假设正向卷积时选取的是3x3的卷积核，且没有填补图像边缘，那么卷积完成后得到的是一个2x2的矩阵；反过来要从一个2x2的矩阵得到一幅4x4的图像/矩阵，如果也是使用3x3的卷积核，就需要对2x2的矩阵边缘做填补（一般直接填0），填补到一个6x6的矩阵，再做卷积就得到了4x4的矩阵（如下图所示）。这样的卷积层叫做transposed convolutional layer。
   ![transposed convolutional layer](https://i.stack.imgur.com/YyCu2.gif)
   <!--break-->

4. 

Reference

1. [Understanding Generative Adversarial Networks](https://towardsdatascience.com/understanding-generative-adversarial-networks-4dafc963f2ef)

